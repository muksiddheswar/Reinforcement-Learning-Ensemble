# Experiments

To compare the different RL algorithms with each other and ensemble methods,
the agents had to solve five different maze tasks of varying complexity.
For the first experiment,
the agents learned to solve a small base where start, goal and walls were in static position. To do this, they combined RL algorithms with a tabular expression.
For the second to fifth maze,
different dynamic elements were added to the maze.
To circumvent the combination explosion that would occur in a tabular expression,
neural networks were used as function approximators.

<!---

wiering 2008

We performed experiments with five different maze tasks
(one simple and four more complex problems) to compare the
different ensemble methods to the individual algorithms. In
the first experiment, the RL algorithms are combined with
tabular representations and are compared on a small maze
task. In the second experiment a partially observable maze
is used and neural networks as function approximators. In the
third experiment a dynamic maze is used where the obstacles
are not placed at fixed positions and neural network function
approximators are used. In the fourth experiment a dynamic
maze is used where the goal is not placed at a fixed position
and neural networks are used as function approximators. In
the fifth and final experiment a generalized maze [23] task
is used where the goal and the obstacles are not placed at
fixed positions and again neural networks are used as function
approximators.

--->