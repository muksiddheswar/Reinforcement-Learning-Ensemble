<!---

sutton 2018

In the previous section we considered transitions from state to state and learned the
values of states. Now we consider transitions from state–action pair to state–action pair,
and learn the values of state–action pairs. Formally these cases are identical: they are
both Markov chains with a reward process. The theorems assuring the convergence of
state values under TD(0) also apply to the corresponding algorithm for action values:

--->